{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5163b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Lenght:  2001\n",
      "Dataset Shape:  (2001, 21)\n",
      "Dataset:                0     1            2         3   4       5           6      7   \\\n",
      "0  battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep   \n",
      "1            842     0          2.2         0   1       0           7    0.6   \n",
      "2           1021     1          0.5         1   0       1          53    0.7   \n",
      "3            563     1          0.5         1   2       1          41    0.9   \n",
      "4            615     1          2.5         0   0       0          10    0.8   \n",
      "\n",
      "          8        9   ...         11        12    13    14    15         16  \\\n",
      "0  mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  talk_time   \n",
      "1        188        2  ...         20       756  2549     9     7         19   \n",
      "2        136        3  ...        905      1988  2631    17     3          7   \n",
      "3        145        5  ...       1263      1716  2603    11     2          9   \n",
      "4        131        6  ...       1216      1786  2769    16     8         11   \n",
      "\n",
      "        17            18    19           20  \n",
      "0  three_g  touch_screen  wifi  price_range  \n",
      "1        0             0     1            1  \n",
      "2        1             1     0            2  \n",
      "3        1             1     0            2  \n",
      "4        1             0     0            2  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'blue'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 108\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Calling main function\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 108\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[1], line 90\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     88\u001b[0m data \u001b[38;5;241m=\u001b[39m importdata()\n\u001b[0;32m     89\u001b[0m X, Y, X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m splitdataset(data)\n\u001b[1;32m---> 90\u001b[0m clf_gini \u001b[38;5;241m=\u001b[39m train_using_gini(X_train, X_test, y_train)\n\u001b[0;32m     91\u001b[0m clf_entropy \u001b[38;5;241m=\u001b[39m tarin_using_entropy(X_train, X_test, y_train)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Operational Phase\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 48\u001b[0m, in \u001b[0;36mtrain_using_gini\u001b[1;34m(X_train, X_test, y_train)\u001b[0m\n\u001b[0;32m     44\u001b[0m clf_gini \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier(criterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgini\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     45\u001b[0m         random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m,max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, min_samples_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Performing training\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m clf_gini\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clf_gini\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    960\u001b[0m         X,\n\u001b[0;32m    961\u001b[0m         y,\n\u001b[0;32m    962\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    963\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m    964\u001b[0m     )\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:242\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    238\u001b[0m check_X_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    239\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    240\u001b[0m )\n\u001b[0;32m    241\u001b[0m check_y_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 242\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    243\u001b[0m     X, y, validate_separately\u001b[38;5;241m=\u001b[39m(check_X_params, check_y_params)\n\u001b[0;32m    244\u001b[0m )\n\u001b[0;32m    246\u001b[0m missing_values_in_feature_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_missing_values_in_feature_mask(X)\n\u001b[0;32m    248\u001b[0m )\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:617\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m check_X_params:\n\u001b[0;32m    616\u001b[0m     check_X_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefault_check_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_X_params}\n\u001b[1;32m--> 617\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_X_params)\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m check_y_params:\n\u001b[0;32m    619\u001b[0m     check_y_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefault_check_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params}\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    919\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'blue'"
     ]
    }
   ],
   "source": [
    "# Run this program on your local python\n",
    "# interpreter, provided you have installed\n",
    "# the required libraries.\n",
    "\n",
    "# Importing the required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Function importing Dataset\n",
    "def importdata():\n",
    "    balance_data = pd.read_csv('train.csv',sep= ',', header = None)\n",
    "\n",
    "    # Printing the dataswet shape\n",
    "    print (\"Dataset Lenght: \", len(balance_data))\n",
    "    print (\"Dataset Shape: \", balance_data.shape)\n",
    "\n",
    "    # Printing the dataset obseravtions\n",
    "    print (\"Dataset: \",balance_data.head())\n",
    "    return balance_data\n",
    "\n",
    "# Function to split the dataset\n",
    "def splitdataset(balance_data):\n",
    "\n",
    "    # Seperating the target variable\n",
    "    X = balance_data.values[:, 1:5]\n",
    "    Y = balance_data.values[:, 0]\n",
    "\n",
    "    # Spliting the dataset into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split( \n",
    "    X, Y, test_size = 0.3, random_state = 100)\n",
    "\n",
    "    return X, Y, X_train, X_test, y_train, y_test\n",
    "\n",
    "# Function to perform training with giniIndex.\n",
    "def train_using_gini(X_train, X_test, y_train):\n",
    "\n",
    "    # Creating the classifier object\n",
    "    clf_gini = DecisionTreeClassifier(criterion = \"gini\",\n",
    "            random_state = 100,max_depth=3, min_samples_leaf=5)\n",
    "\n",
    "    # Performing training\n",
    "    clf_gini.fit(X_train, y_train)\n",
    "    return clf_gini\n",
    "\n",
    "# Function to perform training with entropy.\n",
    "def tarin_using_entropy(X_train, X_test, y_train):\n",
    "\n",
    "    # Decision tree with entropy\n",
    "    clf_entropy = DecisionTreeClassifier(\n",
    "            criterion = \"entropy\", random_state = 100,\n",
    "            max_depth = 3, min_samples_leaf = 5)\n",
    "\n",
    "    # Performing training\n",
    "    clf_entropy.fit(X_train, y_train)\n",
    "    return clf_entropy\n",
    "\n",
    "\n",
    "# Function to make predictions\n",
    "def prediction(X_test, clf_object):\n",
    "\n",
    "    # Predicton on test with giniIndex\n",
    "    y_pred = clf_object.predict(X_test)\n",
    "    print(\"Predicted values:\")\n",
    "    print(y_pred)\n",
    "    return y_pred\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def cal_accuracy(y_test, y_pred):\n",
    "\n",
    "    print(\"Confusion Matrix: \",\n",
    "        confusion_matrix(y_test, y_pred))\n",
    "    print (\"Accuracy : \",\n",
    "    accuracy_score(y_test,y_pred)*100)\n",
    "\n",
    "    print(\"Report : \",\n",
    "    classification_report(y_test, y_pred))\n",
    "\n",
    "# Driver code\n",
    "def main():\n",
    "\n",
    "    # Building Phase\n",
    "    data = importdata()\n",
    "    X, Y, X_train, X_test, y_train, y_test = splitdataset(data)\n",
    "    clf_gini = train_using_gini(X_train, X_test, y_train)\n",
    "    clf_entropy = tarin_using_entropy(X_train, X_test, y_train)\n",
    "\n",
    "    # Operational Phase\n",
    "    print(\"Results Using Gini Index:\")\n",
    "\n",
    "    # Prediction using gini\n",
    "    y_pred_gini = prediction(X_test, clf_gini)\n",
    "    cal_accuracy(y_test, y_pred_gini)\n",
    "\n",
    "    print(\"Results Using Entropy:\")\n",
    "    # Prediction using entropy\n",
    "    y_pred_entropy = prediction(X_test, clf_entropy)\n",
    "    cal_accuracy(y_test, y_pred_entropy)\n",
    "\n",
    "\n",
    "# Calling main function\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6526bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 702. 1645. 1030.  921.  880. 1251. 1230.  790. 1023. 1333.  955. 1396.\n",
      "  674.  877. 1498. 1177.  615.  858.  578. 1560. 1029. 1077.  545. 1560.\n",
      "  641.  846. 1162. 1064.  987. 1367.  918.  835. 1656. 1954.  531.  775.\n",
      " 1702. 1762.  507. 1163.  545. 1122. 1604.  626. 1030.  511.  763. 1031.\n",
      " 1441.  826.  628. 1109.  742.  543. 1775. 1193. 1715.  545.  625. 1158.\n",
      " 1177.  627. 1617. 1030.  946. 1092.  671.  869. 1541. 1748.  912.  508.\n",
      " 1317. 1189.  914.  831.  553. 1617. 1472. 1563. 1567. 1184.  545. 1202.\n",
      "  914. 1659. 1136. 1779.  742. 1333.  694. 1269.  869.  516. 1512.  972.\n",
      "  547.  748.  871.  674. 1583.  574. 1948. 1528.  757.  621.  907. 1251.\n",
      " 1953.  793. 1072.  560.  605. 1680.  720. 1538.  508.  510. 1368.  582.\n",
      "  531.  543.  531.  557.  660.  705.  531.  880.  504. 1166. 1659.  790.\n",
      "  848. 1162. 1765. 1166.  508. 1278.  712.  574.  534. 1550. 1159.  685.\n",
      " 1583.  869. 1479. 1156. 1702. 1766.  972.  897. 1367.  922.  696. 1497.\n",
      " 1170.  899.  580. 1948.  858. 1726. 1253.  772.  973.  726.  721. 1330.\n",
      " 1646. 1352.  557. 1063.  987.  885.  871. 1514. 1392.  763.  545. 1330.\n",
      " 1358. 1030. 1854. 1646. 1030. 1807. 1122. 1860.  840. 1181. 1438. 1991.\n",
      "  510.  955.  783. 1954.  605.  553. 1083. 1081. 1143. 1479. 1224. 1327.\n",
      "  545.  742. 1083.  643. 1884.  863.  989. 1131. 1163. 1760. 1278. 1195.\n",
      " 1775.  809. 1775. 1230. 1042.  848. 1537.  545. 1726.  850. 1441.  618.\n",
      "  728.  725.  880.  594. 1278.  925. 1766. 1821.  569.  767. 1479.  531.\n",
      "  668.  827.  615.  955.  742. 1723.  600. 1312. 1676.  729.  605. 1560.\n",
      "  503.  730. 1397.  504. 1644. 1358.  530.  817.  584.  955. 1854.  899.\n",
      " 1554. 1537.  721. 1144.  633. 1308.  605.  869.  990. 1441.  869.  671.\n",
      " 1392. 1108.  659. 1732. 1644.  531.  733.  589.  705.  648.  807. 1511.\n",
      " 1163. 1251. 1367. 1726.  581.  569. 1128.  709. 1251. 1412.  831. 1644.\n",
      " 1156. 1692.  790. 1092.  557.  717. 1718. 1030. 1103.  514.  946. 1596.\n",
      "  769.  504. 1646. 1953. 1723.  645.  936.  545. 1322.  547.  671.  531.\n",
      "  703.  574. 1936.  914. 1436.  987. 1081. 1029. 1846. 1059.  729. 1433.\n",
      " 1380.  864. 1194. 1454.  574. 1097.  638. 1453.  581. 1368. 1569. 1063.\n",
      "  732.  640.  581. 1031.  718.  535. 1053. 1537.  984.  557.  654.  674.\n",
      "  877.  729. 1158.  571.  904.  535. 1872. 1015. 1617. 1963.  787. 1367.\n",
      " 1397.  673. 1027.  850. 1479. 1524.  871. 1159.  534.  907.  513.  722.\n",
      " 1742.  594. 1646. 1642. 1645. 1205. 1034.  728.  663.  504. 1807.  856.\n",
      "  584. 1438.  545.  922.  858.  922. 1807. 1671. 1154.  674.  799. 1766.\n",
      "  531. 1156.  895.  543.  732. 1680.  531. 1692. 1162. 1766.  717.  877.\n",
      "  880. 1584. 1216. 1610.  593.  767. 1398. 1957.  983.  659.  660.  728.\n",
      "  906.  593. 1109. 1843. 1533. 1648. 1936.  672.  603. 1423. 1530. 1424.\n",
      "  642. 1074.  890.  695.  733. 1692. 1367.  688.  930. 1184.  618.  906.\n",
      " 1864. 1355.  593.  580. 1224. 1864. 1319. 1846. 1436.  545. 1645.  881.\n",
      " 1224.  548.  531.  531.  593.  663.  856.  586.  722. 1181.  890.  586.\n",
      "  742. 1122.  863.  508.  839.  685. 1131. 1205.  718.  748. 1841. 1064.\n",
      " 1367. 1522.  582.  732.  771. 1407. 1775.  548. 1595. 1029. 1424.  955.\n",
      " 1760. 1441. 1095.  644.  983.  797. 1485.  557.  759.  516.  638.  850.\n",
      " 1646.  605.  576. 1030. 1195. 1616.  504.  589. 1095.  545. 1760. 1314.\n",
      " 1652.  725.  615.  921.  605. 1766.  904. 1538. 1554.  852.  726.  729.\n",
      " 1367.  663. 1790.  862.  589. 1314.  545.  907. 1998. 1834.  797.  987.\n",
      " 1748.  601. 1104.  574.  769.  742. 1472. 1584. 1162. 1108.  508. 1230.\n",
      " 1224.  864.  637. 1522. 1827.  553. 1642. 1876. 1018. 1483. 1369.  705.\n",
      "  600.  510.  508.  732.  926. 1537.  509.  742. 1530. 1361.  912.  846.\n",
      "  609.  657. 1496.  534. 1265. 1131.  868. 1472.  673.  508.  863. 1367.]\n",
      "0\n",
      "1400\n",
      "Gini : 0.3466666666666667\n",
      "Accuracy is:  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('C:/Users/saura/Downloads/archive/train.csv')\n",
    "X = data.values[:, 1:5]\n",
    "Y = data.values[:, 0]\n",
    "#X, t = make_classification(100, 5, n_classes=2, shuffle=True, random_state=10)\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, Y, test_size=0.3, shuffle=True, random_state=1)\n",
    "\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model = model.fit(X_train, t_train)\n",
    "\n",
    "predicted_value = model.predict(X_test)\n",
    "print(predicted_value)\n",
    "\n",
    "tree.plot_tree(model)\n",
    "\n",
    "zeroes = 0\n",
    "ones = 0\n",
    "for i in range(0, len(t_train)):\n",
    "\tif t_train[i] == 0:\n",
    "\t\tzeroes += 1\n",
    "\telse:\n",
    "\t\tones += 1\n",
    "\n",
    "print(zeroes)\n",
    "print(ones)\n",
    "\n",
    "val = 1 - ((zeroes/1000)*(zeroes/300) + (ones/1000)*(ones/3000))\n",
    "print(\"Gini :\", val)\n",
    "\n",
    "match = 0\n",
    "UnMatch = 0\n",
    "\n",
    "for i in range(30):\n",
    "\tif predicted_value[i] == t_test[i]:\n",
    "\t\tmatch += 1\n",
    "\telse:\n",
    "\t\tUnMatch += 1\n",
    "\n",
    "accuracy = match/3000\n",
    "print(\"Accuracy is: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18a6d61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
